#!/usr/bin/env python3

import click
import datetime
import infer
import neural_network
import os
import os.path
#~ from run_albacore import run_albacore
import shutil
import split_f5
import subprocess
from sys import argv

"""
Main script to run tool from 
"""
@click.command()
@click.option("--input-dir", "-i", help="Path to input directory of reads in FAST5 format")
@click.option("--split-dir", "-s", help="Path to directory to save split reads to")
#~ @click.option("--save-dir", "-s", help="Directory to save basecalled reads to")  save_dir, 
@click.option("--chunk-size", "-c", help="Chunk size for homopolymer containing stretches", default=1000, show_default=True)
def main(input_dir, split_dir, chunk_size, threshold=0.9, network_path="ResNetRNN", network_type="ResNetRNN"):
    # /home/thijs030/thesis/scripts/
    """
    A tool with a neural network as basis to predict the presence of 
    homopolymers in the raw signal from a MinION sequencer. 
    """
    # initialise variables for saving information
    hp_dict = {}
    nonhp_dict = {}
    files_hp = []
    files_nonhp = []
    temp_dir = "{}/TEMP".format(os.path.abspath(split_dir))
    temp_dir_hp = "{}/HP".format(os.path.abspath(temp_dir))
    temp_dir_nonhp = "{}/nonHP".format(os.path.abspath(temp_dir))
    os.makedirs(temp_dir_hp)
    os.mkdir(temp_dir_nonhp)
    save_dir_hp = split_dir + "/HP"
    save_dir_nonhp = split_dir + "/nonHP"

    # 0. Load model
    t1 = datetime.datetime.now()
    network_path = os.path.abspath(network_path)
    model = neural_network.load_network(network_type, network_path, checkpoint=30000)
    print("Loaded model in {}".format(datetime.datetime.now() - t1))
    
    # 1. Load files in directory
    input_dir = os.path.abspath(input_dir)
    input_files = os.listdir(input_dir)

    # 2. Get predicted HPs for every read
    print("Checking for homopolymers in raw signal..")
    t2 = datetime.datetime.now()
    for fast5_file in input_files:
        hp_positions, len_read = infer.infer_class_from_signal("{}/{}".format(input_dir, fast5_file), model, label=1)

        if hp_positions != []:
            merged_positions = [hp_positions[0]]
            for i in range(len(hp_positions)):
                if hp_positions[i][1] >= chunk_size + merged_positions[-1][0]:
                    merged_positions[-1][-1] = hp_positions[i - 1][1]
                    center_hp(merged_positions, len_read, chunk_size)
                    merged_positions.append(hp_positions[i])
            center_hp(merged_positions, len_read, chunk_size)
            
            # 2a. Add homopolymers to dict:
            hp_dict[fast5_file] = merged_positions
            
            # 2b. Add non-homopolymers to separate dict:
            m_start = 0
            nonhp_dict[fast5_file] = []
            for m in range(len(merged_positions)):
                if merged_positions[m][0] > m_start:
                    m_end = merged_positions[m][0] - 1
                    nonhp_dict[fast5_file].append([m_start, m_end])
                m_start = merged_positions[m][1]
            if merged_positions[-1][1] != len_read:
                nonhp_dict[fast5_file].append([merged_positions[-1][1], len_read])
        else:                                                                   # to catch reads with no HPs
            nonhp_dict[fast5_file] = [([(0, len_read) , len_read])]

    print("Finished determining possible HP stretches in {}".format(datetime.datetime.now() - t2))

    # 3. Split FAST5 in multiple FAST5s
    print("Splitting reads...")
    t3 = datetime.datetime.now()
    for read in hp_dict:
        hp_files, nonhp_files = split_f5.split_signal("{}/{}".format(input_dir, read), hp_dict[read], nonhp_dict[read], temp_dir_hp, temp_dir_nonhp)
        files_hp.extend(hp_files)                                               # HP files are absolute paths
        files_nonhp.extend(nonhp_files)
    print("Finished splitting the raw signals in {}".format(datetime.datetime.now() - t3))
    
    return hp_files, nonhp_files
    

    # 4. Process each FAST5 belong to HP or non-HP group
    #~ print("Basecalling with Albacore v2.3.3  ..")
    #~ t4 = datetime.datetime.now()
    #~ run_albacore(temp_dir_hp, save_dir_hp, hp_correct=1, chunk_size=chunk_size)
    #~ run_albacore(temp_dir_nonhp, save_dir_nonhp, hp_correct=0, chunk_size=chunk_size)
    #~ print("Finished basecalling in {}".format(datetime.datetime.now() - t4))
           
    # remove temporarily directory for saving split reads:
    #~ shutil.rmtree(temp_dir, ignore_errors=True)
    #~ print("Cleaned up split read files.")
        
    # 5. Extract FASTAs from FASTQs in passed dir / Concatenate reads
    #~ subprocess.run("cat {}/workspace/pass/*.fastq > {}/homopolymer.fastq".format(save_dir_hp, save_dir))
    #~ subprocess.run("cat {}/workspace/pass/*.fastq > {}/nonhomopolymer.fastq".format(save_dir_nonhp, save_dir))
    #~ subprocess.run("cat {}/*.fastq > basecalled.fastq".format(save_dir))
    #~ os.remove("{}/homopolymer.fastq".format(save_dir))
    #~ os.remove("{}/nonhomopolymer.fastq".format(save_dir))
    
    #~ shutil.rmtree(save_dir_hp, ignore_errors=True)
    #~ shutil.rmtree(save_dir_nonhp, ignore_errors=True)
    
    #~ print("Finished processes. FASTQ containing all reads can be found at {}.".format(os.path.abspath(save_dir)))


def center_hp(merged_positions, len_read, chunk_size=1000):
    len_hp = merged_positions[-1][-1] - merged_positions[-1][0]
    if len_hp < chunk_size:
        left_padding = (chunk_size - len_hp) // 2
        right_padding = (chunk_size - len_hp) - left_padding
        merged_positions[-1][0] = merged_positions[-1][0] - left_padding
        merged_positions[-1][1] = merged_positions[-1][1] + right_padding
        if merged_positions[-1][0] < 0:
            merged_positions[-1][1] -= merged_positions[-1][0]
            merged_positions[-1][0] = 0
        if merged_positions[-1][1] > len_read: 
            merged_positions[-1][0] -= len_read - merged_positions[-1][1]     
            merged_positions[-1][1] = len_read
    
    return merged_positions

    
if __name__ == "__main__":
    main()
    




